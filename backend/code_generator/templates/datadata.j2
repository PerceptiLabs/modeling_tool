{% from 'file_utils.j2' import load_npy, load_csv, load_img_dir %}

# Create file generators
np.random.seed({{seed}})
batch_size = {{batch_size}}

global trn_gens_args_{{layer_id}}, val_gens_args_{{layer_id}}, tst_gens_args_{{layer_id}} # TODO: once we stop using 'exec' we can get rid of all globals and layer id tags.
trn_gens_args_{{layer_id}}, val_gens_args_{{layer_id}}, tst_gens_args_{{layer_id}} = [], [], []
trn_sz_tot, val_sz_tot, tst_sz_tot = 0, 0, 0
columns = {}
sources = {{sources}}

{#
{% if not lazy %}
    {% filter remove_lspaces(8) %}
        if api.insights.predict_memory_depletion(sources):
            api.ui.render('out-of-memory-warning')
            api.log.warning('This data set could cause the system to run out of memory. Consider enable lazy handling of the data')
    {% endfilter %}
{% endif %}
#}

{% filter remove_lspaces(8) %}
    {% for idx, source, partition in zip(range(0, len(sources)), sources, partitions): %}
        {% set tag = str(layer_id) + '_' + str(idx) %}

        columns_{{tag}} = None
        {# The following block highlights a quirk in Jinja2. The macro calls are indented by 16 spaces, #}
        {# but only the first line of the macro will inherit that indent. #}
        {# Solution: #}
        {# Apply the 'indent' filter with 16 spaces. This will align the subsequent macro lines (it ignores the first #}
        {# Now we can remove the spaces properly using the 'remove_lspaces' filter #}
    
        {% filter remove_lspaces(8) %}
            {% if source['type'] == 'file' and source['ext'] in ['.npy', '.npz'] %}
                {{ load_npy(source['path'], tag) | indent(width=16)}}
            {% elif source['type'] == 'file' and source['ext'] in ['.csv', '.txt'] %}
                {{ load_csv(source['path'], tag, lazy, selected_columns) | indent(width=16)}}
            {% elif source['type'] == 'directory' and source['ext'] in ['.jpg', '.png', '.jpeg', '.tif', '.tiff'] %}
                {{ load_img_dir(source['path'], tag) | indent(width=16)}}
            {% endif %}
        {% endfilter %}

        if columns_{{tag}} is not None:
            columns["{{tag}}"] = columns_{{tag}}

        trn_sz = int(round({{partition[0]}}*size_{{tag}}))
        val_sz = int(round({{partition[1]}}*size_{{tag}}))
        tst_sz = int(size_{{tag}} - trn_sz - val_sz)

        trn_sz_tot += trn_sz
        val_sz_tot += val_sz
        tst_sz_tot += tst_sz
        
        trn_gens_args_{{layer_id}}.append((generator_{{tag}}, 0, trn_sz))
        val_gens_args_{{layer_id}}.append((generator_{{tag}}, trn_sz, trn_sz+val_sz))
        tst_gens_args_{{layer_id}}.append((generator_{{tag}}, trn_sz+val_sz, trn_sz+val_sz+tst_sz))
    {% endfor %}
{% endfilter %}

# Chain the generators together
def make_generator_trn_{{layer_id}}():
    global trn_gens_args_{{layer_id}}
    def gen():
        for fn, lo, hi in trn_gens_args_{{layer_id}}:
            yield from fn(lo, hi)
    return gen()

def make_generator_val_{{layer_id}}():
    global val_gens_args_{{layer_id}}
    def gen():
        for fn, lo, hi in val_gens_args_{{layer_id}}:
            yield from fn(lo, hi)
    return gen()

def make_generator_tst_{{layer_id}}():
    global tst_gens_args_{{layer_id}}
    def gen():
        for fn, lo, hi in tst_gens_args_{{layer_id}}:
            yield from fn(lo, hi)
    return gen()

shapes = [next(fn(lo, hi)).shape for fn, lo, hi in trn_gens_args_{{layer_id}}]
if len(set(shapes)) > 1:
    raise ValueError("Shape mismatch! Yielded shapes were: " + str(shapes))

# Make some values available for the frontend
# TODO: Look over this. A proper interface would make this more robust
sample = _sample = next(make_generator_trn_{{layer_id}}())
cols = next(iter(columns.values()), []) # Just get the first (or empty) for now.
global _data_size # apparently trainnormal depends on this...
_data_size = np.array([trn_sz_tot, val_sz_tot, tst_sz_tot])
_partition_summary = list(_data_size*100/_data_size.sum())
_data_size = _data_size.tolist()
api.data.store(batch_size=batch_size)

# Set up datasets
X_trn = tf.data.Dataset.from_generator(make_generator_trn_{{layer_id}},
                                         output_shapes=sample.shape, output_types=np.float32)

X_val = tf.data.Dataset.from_generator(make_generator_val_{{layer_id}},
                                         output_shapes=sample.shape, output_types=np.float32)

X_tst = tf.data.Dataset.from_generator(make_generator_tst_{{layer_id}},
                                        output_shapes=sample.shape, output_types=np.float32)

{% filter remove_lspaces(8) %}
    {% if shuffle and shuffle_buffer_size is none %}
        X_trn = X_trn.shuffle(trn_size_{{layer_id}}, seed={{seed}}).batch(batch_size)            
    {% elif shuffle and shuffle_buffer_size is not none %}
        X_trn = X_trn.shuffle({{shuffle_buffer_size}}, seed={{seed}}).batch(batch_size)            
    {% else %}
        X_trn = X_trn.batch(batch_size)            
    {% endif %}
{% endfilter %}
X_val = X_val.batch(batch_size)
X_tst = X_tst.batch(1)

# Create iterators
iterator = tf.data.Iterator.from_structure(X_trn.output_types, X_trn.output_shapes)

trn_init = iterator.make_initializer(X_trn, name='train_iterator_{{layer_id}}')
val_init = iterator.make_initializer(X_val, name='validation_iterator_{{layer_id}}')            
tst_init = iterator.make_initializer(X_tst, name='test_iterator_{{layer_id}}')
            
Y = iterator.get_next()


